{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea8d47b",
   "metadata": {},
   "source": [
    "### Text Preprocessing - Tokenize into sentences, normalize text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29b3943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = [s.strip() for s in text.strip().split('.') if s.strip()]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    normalized = [s.lower().translate(table) for s in sentences]\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5b514",
   "metadata": {},
   "source": [
    "### Levenshtein Distance function for edit distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ff82d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e8607a",
   "metadata": {},
   "source": [
    "### A* search algorithm for text alignment\n",
    "\n",
    "-   Adaptive heuristic for A* text alignment (drop-in compatible version).\n",
    "\n",
    "-   Automatically chooses between exact Levenshtein and length-based approximation based on remaining sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a32e1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class State:\n",
    "    def __init__(self, i, j, g_cost, path):\n",
    "        self.i = i  \n",
    "        self.j = j\n",
    "        self.g_cost = g_cost\n",
    "        self.path = path\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.g_cost < other.g_cost\n",
    "\n",
    "def heuristic(i, j, doc1, doc2):\n",
    "    max_exact_pairs = 12   \n",
    "    scale_factor = 0.5     \n",
    "\n",
    "    remaining1 = doc1[i:]\n",
    "    remaining2 = doc2[j:]\n",
    "    n1, n2 = len(remaining1), len(remaining2)\n",
    "\n",
    "    # If one doc is exhausted, return total remaining char length as lower bound\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return sum(len(s) for s in remaining1) + sum(len(s) for s in remaining2)\n",
    "\n",
    "    if n1 * n2 <= max_exact_pairs:\n",
    "        # Exact minimal Levenshtein match\n",
    "        min_dists = []\n",
    "        for s1 in remaining1:\n",
    "            min_cost = min(levenshtein_distance(s1, s2) for s2 in remaining2)\n",
    "            min_dists.append(min_cost)\n",
    "        estimate = sum(min_dists)\n",
    "    else:\n",
    "        # Fast approximation: use length differences\n",
    "        estimate = 0\n",
    "        for s1 in remaining1:\n",
    "            len_diffs = [abs(len(s1) - len(s2)) for s2 in remaining2]\n",
    "            estimate += min(len_diffs) if len_diffs else len(s1)\n",
    "\n",
    "    return estimate * scale_factor\n",
    "\n",
    "\n",
    "def neighbors(state, doc1, doc2):\n",
    "    i, j = state.i, state.j\n",
    "    neighbors = []\n",
    "    len1, len2 = len(doc1), len(doc2)\n",
    "    # Align current sentences if both available\n",
    "    if i < len1 and j < len2:\n",
    "        cost = levenshtein_distance(doc1[i], doc2[j])\n",
    "        neighbors.append(('align', i+1, j+1, cost))\n",
    "    # Skip sentence in doc1\n",
    "    if i < len1:\n",
    "        cost = len(doc1[i]) \n",
    "        neighbors.append(('skip_doc1', i+1, j, cost))\n",
    "    # Skip sentence in doc2\n",
    "    if j < len2:\n",
    "        cost = len(doc2[j])\n",
    "        neighbors.append(('skip_doc2', i, j+1, cost))\n",
    "    return neighbors\n",
    "\n",
    "def a_star_search(doc1, doc2):\n",
    "    start = State(0, 0, 0, [])\n",
    "    heap = []\n",
    "    heapq.heappush(heap, (start.g_cost + heuristic(0, 0, doc1, doc2), start))\n",
    "    visited = set()\n",
    "    while heap:\n",
    "        f_cost, current = heapq.heappop(heap)\n",
    "        if (current.i, current.j) in visited:\n",
    "            continue\n",
    "        visited.add((current.i, current.j))\n",
    "        # Goal check\n",
    "        if current.i >= len(doc1) and current.j >= len(doc2):\n",
    "            return current.path, current.g_cost\n",
    "        for action, ni, nj, cost in neighbors(current, doc1, doc2):\n",
    "            if (ni, nj) not in visited:\n",
    "                new_path = current.path.copy()\n",
    "                if action == 'align':\n",
    "                    new_path.append((current.i, current.j, cost))\n",
    "                elif action == 'skip_doc1':\n",
    "                    new_path.append((current.i, None, cost))\n",
    "                else:  # skip_doc2\n",
    "                    new_path.append((None, current.j, cost))\n",
    "                g_cost_new = current.g_cost + cost\n",
    "                new_state = State(ni, nj, g_cost_new, new_path)\n",
    "                heapq.heappush(heap, (g_cost_new + heuristic(ni, nj, doc1, doc2), new_state))\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19546b",
   "metadata": {},
   "source": [
    "### Detect plagiarism based on alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d823f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_plagiarism(alignment, doc1, doc2, threshold=5):\n",
    "    # threshold: max edit distance to consider as plagiarism\n",
    "    plagiarized_pairs = []\n",
    "    for i, j, cost in alignment:\n",
    "        if i is not None and j is not None and cost <= threshold:\n",
    "            plagiarized_pairs.append((doc1[i], doc2[j], cost))\n",
    "    return plagiarized_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf37d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(doc1, doc2, threshold=5):\n",
    "    sentences1 = preprocess_text(doc1)\n",
    "    sentences2 = preprocess_text(doc2)\n",
    "    alignment, total_cost = a_star_search(sentences1, sentences2)\n",
    "    print(f\"Total alignment cost: {total_cost}\")\n",
    "    plag_pairs = detect_plagiarism(alignment, sentences1, sentences2, threshold)\n",
    "    for s1, s2, c in plag_pairs:\n",
    "        print(f\"Potential plagiarism:\\nDoc1: {s1}\\nDoc2: {s2}\\nEdit Distance: {c}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75f92f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1: Identical Documents\n",
    "doc1_test1 = (\n",
    "    \"We propose a new simple network architecture, the Transformer, \"\n",
    "    \"based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. \"\n",
    "    \"Experiments on two machine translation tasks show these models to be superior in quality \"\n",
    "    \"while being more parallelizable and requiring significantly less time to train.\"\n",
    ")\n",
    "\n",
    "doc2_test1 = (\n",
    "    \"We propose a new simple network architecture, the Transformer, \"\n",
    "    \"based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. \"\n",
    "    \"Experiments on two machine translation tasks show these models to be superior in quality \"\n",
    "    \"while being more parallelizable and requiring significantly less time to train.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Test Case 2: Slightly Modified Documents\n",
    "doc1_test2 = (\n",
    "    \"We propose a new simple network architecture, the Transformer, \"\n",
    "    \"based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. \"\n",
    "    \"Experiments on two machine translation tasks show these models to be superior in quality \"\n",
    "    \"while being more parallelizable and requiring significantly less time to train.\"\n",
    ")\n",
    "\n",
    "doc2_test2 = (\n",
    "    \"We propose a novel network design, the Transformer, \"\n",
    "    \"built purely on attention mechanisms, eliminating recurrence and convolutions completely. \"\n",
    "    \"Experiments on machine translation tasks demonstrate these models to be better in performance \"\n",
    "    \"while being more parallelizable and taking much less time to train.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Test Case 3: Completely Different Documents\n",
    "doc1_test3 = (\n",
    "    \"The Transformer relies entirely on self-attention to draw global dependencies between input and output. \"\n",
    "    \"This design removes recurrence completely, enabling parallel computation.\"\n",
    ")\n",
    "\n",
    "doc2_test3 = (\n",
    "    \"Convolutional neural networks are designed to capture spatial hierarchies in image data. \"\n",
    "    \"Recurrent models, on the other hand, are well suited for sequential information such as text or speech.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Test Case 4: Partial Overlap\n",
    "doc1_test4 = (\n",
    "    \"We inspect attention distributions from our models and present and discuss examples in the appendix. \"\n",
    "    \"Our model achieves 28.4 BLEU on the WMT 2014 English–German translation task, \"\n",
    "    \"improving over the existing best results including ensembles by over 2 BLEU.\"\n",
    ")\n",
    "\n",
    "doc2_test4 = (\n",
    "    \"We inspect attention distributions from our models and show illustrative examples in the appendix. \"\n",
    "    \"On the WMT 2014 English–German translation task, our Transformer achieves 28.4 BLEU, \"\n",
    "    \"surpassing previous best scores and ensemble methods.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18ba5baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Identical Documents\n",
      "Total alignment cost: 0\n",
      "Potential plagiarism:\n",
      "Doc1: we propose a new simple network architecture the transformer based solely on attention mechanisms dispensing with recurrence and convolutions entirely\n",
      "Doc2: we propose a new simple network architecture the transformer based solely on attention mechanisms dispensing with recurrence and convolutions entirely\n",
      "Edit Distance: 0\n",
      "\n",
      "Potential plagiarism:\n",
      "Doc1: experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train\n",
      "Doc2: experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train\n",
      "Edit Distance: 0\n",
      "\n",
      "Test Case 2: Slightly Modified Documents\n",
      "Total alignment cost: 94\n",
      "Test Case 3: Completely Different Documents\n",
      "Total alignment cost: 152\n",
      "Test Case 4: Partial Overlap\n",
      "Total alignment cost: 163\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Case 1: Identical Documents\")\n",
    "run_test(doc1_test1, doc2_test1)\n",
    "\n",
    "print(\"Test Case 2: Slightly Modified Documents\")\n",
    "run_test(doc1_test2, doc2_test2)\n",
    "\n",
    "print(\"Test Case 3: Completely Different Documents\")\n",
    "run_test(doc1_test3, doc2_test3)\n",
    "\n",
    "print(\"Test Case 4: Partial Overlap\")\n",
    "run_test(doc1_test4, doc2_test4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e4bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
